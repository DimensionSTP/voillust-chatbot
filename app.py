import os

from dotenv import load_dotenv
import streamlit as st
from audio_recorder_streamlit import audio_recorder
from streamlit_float import *

from src.utils import Utils


load_dotenv()
api_key = os.getenv("openai_api_key")
utils = Utils(api_key=api_key)

float_init()

def initialize_session_state():
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì˜¤ëŠ˜ë„ ë„ì™€ë“œë¦´ê²Œìš”!"}
        ]
initialize_session_state()

st.title("ì¼ëŸ¬ìŠ¤íŠ¸ë¥¼ ë„ì™€ì£¼ëŠ” ìŒì„± ì±—ë´‡ ğŸ¤–")
st.info("ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆ„ë¥´ê³  ë§ˆì´í¬ì— ë§í•´ì£¼ì„¸ìš”.")
st.info("ê·¸ë¦¼ì„ ë³´ê³ ì‹¶ìœ¼ë©´ ê·¸ë ¤ì¤˜! í˜¹ì€ ê·¸ë ¤ì¤„ë˜!ë¼ê³  ë§í•´ë³´ì„¸ìš”.")

footer_container = st.container()
with footer_container:
    audio_bytes = audio_recorder()

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

if audio_bytes:
    with st.spinner("ìŒì„± ì¸ì‹ ì¤‘..."):
        webm_file_path = "temp_audio.mp3"
        with open(webm_file_path, "wb") as f:
            f.write(audio_bytes)

        transcript = utils.stt(webm_file_path)
        if transcript:
            st.session_state.messages.append({"role": "user", "content": transcript})
            with st.chat_message("user"):
                st.write(transcript)
            os.remove(webm_file_path)

if st.session_state.messages[-1]["role"] != "assistant":
    with st.chat_message("assistant"):
        if ("ê·¸ë ¤ì¤˜" in transcript) or ("ê·¸ë ¤ì¤„ë˜" in transcript):
            with st.spinner("ê·¸ë¦¼ì„ ê·¸ë¦¬ëŠ” ì¤‘ì´ì—ìš”!"):
                final_response = "ì–´ë•Œìš”? ë§ˆìŒì— ë“œì‹œë‚˜ìš”?"
                utils.get_image(transcript)
                audio_file = utils.tts(final_response)
                utils.autoplay_audio(audio_file)
        else:
            with st.spinner("ìƒê° ì¤‘ì´ì—ìš”ğŸ¤”..."):
                final_response = utils.get_answer(st.session_state.messages)
            with st.spinner("ê³§ ë‹µë³€í•´ë“œë¦´ê²Œìš”!..."):    
                audio_file = utils.tts(final_response)
                utils.autoplay_audio(audio_file)
        st.write(final_response)
        st.session_state.messages.append({"role": "assistant", "content": final_response})
        os.remove(audio_file)

footer_container.float("bottom: 0rem;")